{"componentChunkName":"component---src-templates-category-tsx","path":"/posts/daily/","result":{"pageContext":{"currentCategory":"daily","categories":["All","algorithm","daily","review","devops","vision"],"edges":[{"node":{"frontmatter":{"title":"23.03.28","date":"2023-03-28T00:00:00.000Z","moment":"2 years ago","thumbnail":null,"tags":["daily"],"category":"daily"},"excerpt":"2달 만에 글을 쓴다. 2달 동안 무엇을 했을까\n\n학교\n\n일단 개강했다. 굳이 따로 공부하진 않았다. 이제 시험 기간이니 조금씩 해야 한다. 컴네와 확랜변만 공부하면 된다. 확랜변은…","id":"c5d992a3-27b7-5256-b512-d9a8508e8c06","body":"\n# 23.03.28\n\n2달 만에 글을 쓴다.\n\n2달 동안 무엇을 했을까\n\n## 학교\n\n 일단 개강했다. 굳이 따로 공부하진 않았다. 이제 시험 기간이니 조금씩 해야 한다. [컴네](http://www.yes24.com/Product/Goods/93997435)와 [확랜변](http://www.yes24.com/Product/Goods/72336483)만 공부하면 된다. 확랜변은 공부 안 해도 될 것 같고 컴네는 이전에 읽었던 내용을 다시 상기시켜야 한다. 근데 조금 시간이 부족한 느낌이 있지만 성적은 그렇게 중요하지 않기에 가볍게 가자.\n\n 교양 과목으로 미술 치료라는 과목을 수강하고 있다. 강의에 대한 평가가 재밌고 유익하다는 평이 많았고 나도 궁금하기에 신청했다. 교수님 말을 계속 듣고 있다가 중간마 의문이 든다. 구체적인 상황을 드는 때도 있지만 아닌 경우, 예를 들면 “자기 자신만 상대방을 공감했다”라는 말을 했는데 왜 그런 상황이 나왔는지 그러면 그 피상담자와 상담한 다른 상담사들은 이상한 건지 그리고 피상담자의 말을 모두 신용하는 게 옳은 것인지 궁금했다. 또한 그림 해석을 하면서 사실 대충 유추할 수 있는 부분이 상당수였다. 조금 신기했던 것은 가족 그림을 그리는 테스트였는데(KFD 그림검사) 나는 그리기 전 무엇을 그려야 할 지 어떤 모습을 그릴지 미리 경우를 나눠 놓고 그렸지만, 당연히 현재(아니면 최근) 가족의 모습을 그려야 한다고 생각했다. 하지만 과거 자신이 행복했던 모습을 그리는 경우도 존재했기에 이 부분은 의외였다. 과거 그림을 그리는 경우는 과거에 의존하고 있다는 것을 보여준다(?) 이렇게 보면 생각할 게 전공 수업보다 재밌게 듣고 있는 거 같기도 하다.ㅋㅋ\n\n## Coding\n\n chatGPT 영향력이 커졌다. GPT-4까지 나온 지금, 구글은 Bard, facebook은 llama(얘는 현재 github에 많다) 등 generation model에 열성이다. api를 사용해서 앱을 만들까 했는데 좋은 생각이 없어서 하지 않았다. 너무 거대하고 똑똑한 모델이 어떻게 생겼을까 GPT-4 모델 공개를 간절히 기다린다…\n\ncaptstone design 프로젝트로 ViT encoder와 Transformer Decoder를 결합한 capthca recognition을 만들려고 했다. 하지만 찾아보니까 이미 [TrOCR(21.09)](https://huggingface.co/docs/transformers/model_doc/trocr) 이라는 모델이 이미 존재했다. 생각해보면 내가 하려는 작업이 OCR인데 미리 OCR을 찾아보지 않고 captcha에만 집중해서 conv 모델들만 있는 속도가 더딘 Task라고 생각한 게 조금 아쉽다. torch로 모델도 짜봤지만 잘 학습이 되지 않았다. 먼저 TrOCR 모델로 내가 모은 데이터셋으로 학습을 돌리고 있는데 기존 방식보다 정확도를 많이 높일 수 있지만 속도 측면에서 느려진다. 최적화를 해보고 결과를 비교해봐야겠다.\n\nlab 과제는 계속 하고 있다. 가장 최근에 23년 재선충 데이터셋을 받았는데 다운로드 속도도 느리고 파일도 커서 일주일 동안 조금씩 받았던 거 같다. 오늘 막 다 받았는데 약간 문제가 있다. object_class가 늘어났다는 것이다. 기존에 multi class이면 single_class라고 생각해서 만든 모델들을 쓸 수 없다. 다시 만들어야 하지만 왜 multi class로 나눴는지 이해하지 못하겠다. 일단 메일을 보냈으니 정보를 더 얻고 진행해야겠다.\n\nobject-detction에서 imbalance dataset에 관한 논문을 읽었다. 근데 비교해봐도 single-class라서 제외되는 경우가 많았다. 몇 개 쓸만했지만 이는 augmentation(crop, mosaic)으로 해결할 수 있다. 하지만 이 논문을 읽은 이유는 다른 이유가 있는데 객체가 없는 데이터셋을 많이 넣으 모델 성능에 영향이 갈 것인가? 사실 지금 생각해보면 영향이 갈 이유가 없는 것 같다. 오픈 카톡방에 물어봐도 이상한 질문이라고 생각하는 것 같았다. CNN backbone 특성상 상관없을 것 같다. 요번 주 발표가 길어질 수도 있지만 이 내용을 정리해서 발표해야겠다.\n\n사실 몇 개 repo를 더 파서 toy project도 만들었는데 너무 많아서 설명하긴 귀찮다.\n\n## 책\n\n 초반에는 주식 관련 책을 읽었다([주식 공부 5일 완성](http://www.yes24.com/Product/Goods/96793810), [경제적 해자](http://www.yes24.com/Product/Goods/97967096)) 약간 남의 일 같이 읽어서 피부에 와닿지 않았다. 따로 시간을 들여 관련 재무를 보는 것이 쉽지가 않다. 특히 kakao 재무표를 보면서 했는데 카카오는 음… IT 기업 위주로 list를 뽑아서 분석하는 repo를 만들어야겠다. 그러다 도서관에서 [차별에 관한 책](http://www.yes24.com/Product/Goods/76470464)을 읽었다. 전체적으로 글이 작가의 생각을 담은 답을 주진 않았다. 무엇이 옳고 그른가는 내가 판단해야 했기에 조금 답답했지만 나도 “Yes” or “No”로 답하지 못할 것 같다. 또 의도치 않은 차별 부분을 상기시켜 줬다. 예시는 조금 더 생각해서 그에 대한 답을 찾으면 적어야겠다.\n\n 마지막으로 지금 읽고 있는 책인데 “[세이노의 가르침](http://www.yes24.com/Product/Goods/117014613)”이다. 사실 이 글을 려고 자기 전 컴퓨터를 켰다. 예전에 친구가 읽으라고 추천해 줬는데 제목을 까먹고 읽지 못하다가 최근 밀리에 올라와서 읽고 있는데 생각보다 공격적이다. 솔직히 처음 봤을 때는 글이 공격적이라 충격을 받았고(욕을 쓸 준 몰랐다) 내 자신을 돌아보게 한다. 요즘 나에게 필요한 게 무엇인지 생각을 많이 한다. 그 중 하나가 자존감인데 자존감을 높이라는 글을 자주 보지만 그것이 실제 행동으로 옮기기 어렵고 그런 행동을 하는 나의 모습을 생각하는 것도 힘들다. 덕업일치라고 하나 내가 하고 싶은 일과 실제 하는 일이 같은 것 정말 듣기 좋은 소리다. 2학년 때까지만 해도 나도 그런 줄 알았다. 하지만 점점 이게 맞나는 생각이 들더니 나를 지탱해주던 엔진이 꺼졌다. 과거 밤새서 했던 그런 모습은 사라지고 자기혐오에 빠졌다. 나 자신을 독촉하던 모습이 사라진 6개월 동안 나는 발전한 게 없다. 계획만 있고 실천을 안 하는 모습. 나중에 책이라도 쓰고 싶다 “나는 나 자신을 혐오한다” 캬~ 제목 잘 지었네. 사실 이 책을 읽으면서 내 자신에 대해 반성하고 있다. 지금 내 위치가 바닥도 아닌데 위로 올라갈 생각은 안 하고 다이빙할 준비를 하고 있다는 것에 실망했고 주식 관련 책을 읽으면서 꽁으로 돈을 벌 수 있지 않느냐는 생각을 한 것도 뜨끔했다.(물론 공부는 하면 좋겠지만, 자본도 없이 하는 것이 무슨 의미가 있으랴) 오늘 읽은 문장 중 하나 적어본다.\n\n<aside>\n💡 자기 자신을 사냥의 대상으로 삼는 것이 좀 더 고귀한 스포츠가 아닐까.\n\n</aside>\n\n내 자신을 쫓던 그 모습을 되찾기를 바라며 이 글을 마친다.","fields":{"timeToRead":{"minutes":9.95},"slug":"/posts/2023-03-28/23-03-28/"},"internal":{"contentFilePath":"/home/runner/work/ha4219.github.io/ha4219.github.io/contents/posts/2023-03-28/23-03-28.mdx"}},"next":{"fields":{"slug":"/posts/2023-01-24/23-01-24/"}},"previous":{"fields":{"slug":"/posts/2023-03-30/boj-27924/"}}},{"node":{"frontmatter":{"title":"23.01.24","date":"2023-01-24T00:00:00.000Z","moment":"2 years ago","thumbnail":null,"tags":["daily"],"category":"daily"},"excerpt":"설 연휴 마지막날 일기 생각정리\n\n개인적인 이슈가 크게 터졌다. 원래 연휴 때 낮에 책 읽고 밤에 친구들이랑 게임하려고 했는데 모든 것이 엉망이 됐다. 이슈에 관해서 생각을 진짜…","id":"8fcbb1cd-00d8-5924-b467-63da47bd9d80","body":"\n# 23.01.24\n\n## 설 연휴 마지막날 일기\n\n### 생각정리\n\n 개인적인 이슈가 크게 터졌다. 원래 연휴 때 낮에 책 읽고 밤에 친구들이랑 게임하려고 했는데 모든 것이 엉망이 됐다. 이슈에 관해서 생각을 진짜 많이 했는데 나중에 내 스스로 객관화를 한 후 포스팅해야 겠다.\n\n1. 금요일, 랩 미팅\\\n    기존 모든 이미지를 사용하는 것을 대신해 **지역 별 clustering**을 통해 **동적**으로 데이터셋을 불러와 학습\n    이유: 기존 이미지는 드론으로 여러 장소를 연속으로 측정함. 따라서 한 장소에 오랫동안 데이터 수집을 했을 경우 그 장소에 대해서만 데이터 셋이 많음. 그렇기에 비슷한 데이터를 반복적으로 사용하는 것은 학습에 좋지 않은 결과를 띌 것이다.\n    결과적으로 지역을 clustering할 방법에 대해 찾는다면 가능하다. 이는 내일 찾아봐야 겠다. (분류인가 clustering인가, 분류라면 라벨링을 해야하는 것인가)\n    이미지를 지역별로 분류할 수 있다면 [Dataset](https://pytorch.org/vision/stable/datasets.html)에서 동적으로 이미지를 넘겨줄 수 있을 것이다.(병렬적인 부분은 고려하지 않았다) → `Datasets.__len` = 지역 수?\n2. [js deep dive](http://www.yes24.com/Product/Goods/92742567) 읽기\n    700p까지 읽었으니까 내일 근로 때 적당히 읽으면 될 것 같다.\n3. [운영체제](http://www.yes24.com/Product/Goods/111378840) 책 읽기\n    책 내용이 너무 쉽다. 먼저 js 책 다 읽고 이 책은 포스팅할 거 정리하면서 읽어야겠다.\n4. 토익 문제 풀기\n    진짜 공부해야하는데…\n5. 연구실 짐 옮기기\n    내일 맥북이랑 충전기들만 옮겨서 작업하고 나머지는 천천히 해야될 것 같다.\n\n\n---\n\n[https://github.com/ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)\n\n 좋은 건지 나쁜 건지 모르겠지만 `yolov8`이 나왔다. 처음 프로젝트에 들어갔을 때 `yolov5`가 나와서 이것을 현 프로젝트에 적용시켰는데 해당 저자가 개선된 버전을 올려줬다. 역시나 paper는 없다. 변경 내용은 **모델 개선**(사실 이게 제일 중요한 거 같은데 paper가 없어서 분석이 어려울 것 같다), **패키지 배포** 등이 있는데 지금 가장 중요한 **edgetpu** 모델로 변환할 수 없다.(torch based model) 그래서 당장은 적용할 수 없겠지만 관심을 갖을 필요는 있을 것 같다.\n\n---\n\n[Let's build GPT: from scratch, in code, spelled out.](https://www.youtube.com/watch?v=kCc8FmEb1nY)\n\n Transformer 모델에서 Decoder 부분을 사용해 만들었다는 GPT, 논문을 직접 읽은 것도 아니지만 [Andrej Karpathy](https://karpathy.ai/)가 이를 바닥부터 만드는 영상이다. 재밌을 것 같아서 메모한다.\n\n---\n\n### 하고 싶은 것\n\n- [Goodbye, useEffect](https://www.youtube.com/watch?v=bGzanfKVFeU&t=1113s), review\n- javascript deep dive, review\n- 25일 유퀴즈 곽튜브편 보기\n- 주식 글 정리 및 계획\n- blog 마무리\n- discord bot, game 구현\n","fields":{"timeToRead":{"minutes":3.76},"slug":"/posts/2023-01-24/23-01-24/"},"internal":{"contentFilePath":"/home/runner/work/ha4219.github.io/ha4219.github.io/contents/posts/2023-01-24/23-01-24.mdx"}},"next":{"fields":{"slug":"/posts/2023-01-04/22-reivew/"}},"previous":{"fields":{"slug":"/posts/2023-03-28/23-03-28/"}}}]}},"staticQueryHashes":[],"slicesMap":{}}